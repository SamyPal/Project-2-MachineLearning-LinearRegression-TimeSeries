{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "\n",
    "# Step 1: Sending a HTTP request to a URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "# Make a GET request to fetch the raw HTML content\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "\n",
    "# Step 2: Parse the html content\n",
    "soup = BeautifulSoup(html_content, \"lxml\")\n",
    "# print(soup.prettify()) # print the parsed data of html\n",
    "\n",
    "\n",
    "# Step 3: Analyze the HTML tag, where your content lives\n",
    "# Create a data dictionary to store the data.\n",
    "data = {}\n",
    "#Get the table having the class wikitable\n",
    "gdp_table = soup.find(\"table\", attrs={\"class\": \"wikitable\"})\n",
    "gdp_table_data = gdp_table.tbody.find_all(\"tr\")  # contains 2 rows\n",
    "\n",
    "# Get all the headings of Lists\n",
    "headings = []\n",
    "for td in gdp_table_data[0].find_all(\"td\"):\n",
    "    # remove any newlines and extra spaces from left and right\n",
    "    headings.append(td.b.text.replace('\\n', ' ').strip())\n",
    "print(headings)\n",
    "\n",
    "# Get all the 3 tables contained in \"gdp_table\"\n",
    "for table, heading in zip(gdp_table_data[1].find_all(\"table\"), headings):\n",
    "    # Get headers of table i.e., Rank, Country, GDP.\n",
    "    t_headers = []\n",
    "    for th in table.find_all(\"th\"):\n",
    "        # remove any newlines and extra spaces from left and right\n",
    "        t_headers.append(th.text.replace('\\n', ' ').strip())\n",
    "    \n",
    "    # Get all the rows of table\n",
    "    table_data = []\n",
    "    for tr in table.tbody.find_all(\"tr\"): # find all tr's from table's tbody\n",
    "        t_row = {}\n",
    "        # Each table row is stored in the form of\n",
    "        # t_row = {'Rank': '', 'Country/Territory': '', 'GDP(US$million)': ''}\n",
    "\n",
    "        # find all td's(3) in tr and zip it with t_header\n",
    "        for td, th in zip(tr.find_all(\"td\"), t_headers): \n",
    "            t_row[th] = td.text.replace('\\n', '').strip()\n",
    "        table_data.append(t_row)\n",
    "\n",
    "    # Put the data for the table with his heading.\n",
    "    data[heading] = table_data\n",
    "\n",
    "\n",
    "# Step 4: Export the data to csv\n",
    "\"\"\"\n",
    "For this example let's create 3 seperate csv for \n",
    "3 tables respectively\n",
    "\"\"\"\n",
    "for topic, table in data.items():\n",
    "    # Create csv file for each table\n",
    "    with open(f\"{topic}.csv\", 'w') as out_file:\n",
    "        # Each 3 table has headers as following\n",
    "        headers = [ \n",
    "            \"Country/Territory\",\n",
    "            \"GDP(US$million)\",\n",
    "            \"Rank\"\n",
    "        ] # == t_headers\n",
    "        writer = csv.DictWriter(out_file, headers)\n",
    "        # write the header\n",
    "        writer.writeheader()\n",
    "        for row in table:\n",
    "            if row:\n",
    "                writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
